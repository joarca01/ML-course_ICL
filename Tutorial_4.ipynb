{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joarca01/ML-course_ICL/blob/main/Tutorial_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMGmz3Q-0sY_"
      },
      "source": [
        "# Goal of the tutorial\n",
        "\n",
        "*   Understand convolutional layers\n",
        "*   Implement a convolutional neural network using Pytorch\n",
        "*   Understand what a network learns through data reconstruction\n",
        "*   Understand residual blocks and implement a residual neural network (ResNet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ffb8600"
      },
      "source": [
        "# Loading the libraries and dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "f35648e3"
      },
      "outputs": [],
      "source": [
        "# Let's load the usual libraries\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcsS0__P0whV"
      },
      "source": [
        "For this tutorial, we will use the CIFAR10 dataset. It has the classes: ‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’, ‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’. Each class is of size 6000. The images in CIFAR-10 are of size 3x32x32, i.e. 3-channel color images (red, green and blue) of 32x32 pixels in size. Let's load it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0200f8ca",
        "outputId": "5b40d173-7278-42f9-84a5-6f5d3caa4dc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:08<00:00, 19.5MB/s]\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=0)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=0)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q02iGheK-FDx"
      },
      "source": [
        "Let's visualise one of the images in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "jUJ4MBFI8SKK",
        "outputId": "2bdc629b-467f-4539-b27d-6d0aa1324aae"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Get some random training images; this will load a set of images of size batchsize\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = next(dataiter)\n",
        "img = images[0] # take just the first image; the above thing is an array of images of size batchsize\n",
        "img = img / 2 + 0.5     # unnormalize\n",
        "\n",
        "# Print the original image\n",
        "npimg = img.numpy() # translate to numpy\n",
        "npimg_t = np.transpose(npimg, (1, 2, 0))\n",
        "plt.imshow(npimg_t)\n",
        "plt.title(str(classes[labels[0]]))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fec32da"
      },
      "source": [
        "# Implementing a Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUMYKer21I1f"
      },
      "source": [
        "Let's begin by understanding convolutional layers, which perform transformations of our original images through local weighted averages.\n",
        "\n",
        "We will use the Pytorch conv2d function (https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html) to implement these. It has the following arguments:\n",
        "- in_channels: the number of channels of the input (e.g. a colored image has 3 channels for red, green and blue)\n",
        "- out_channels: the number of channels we want the output to have (i.e. how many times we apply different kernels)\n",
        "- kernel_size: the size of the filter\n",
        "- stride: number of rows/columns traversed every time the filter is applied\n",
        "- padding: size of extra pixels added at edge of image\n",
        "\n",
        "It has some other parameters of which we will use the default modes (and hence we don't specify them):\n",
        "bias = True, dilation = 1.\n",
        "\n",
        "If we have an input $I$ of size $[N, C_{in}, H, W]$, where $N$ is the number of images passed through the layer, $C_{in}$ is the number of channels each image has, and $H$ and $W$ are the height and width of the image, respectively.\n",
        "The output is then computed as,\n",
        "$$\n",
        "O[N_n, C_{out_j}, :, :] = b[C_{out_j}] + \\sum_{i=0}^{C_{in}-1} w[C_{out_j},i]*I[N_n, i, :, :].\n",
        "$$\n",
        "\n",
        "When implementing convolutional layers, it is useful to keep track of the size (height and width) of the images outputted in each layer. In the CIFAR10 dataset we use square images, so height=width.\n",
        "\n",
        "Let us define the following:\n",
        "\n",
        "\n",
        "*   $n_{in}$: height (or width) of input image\n",
        "*   $k$: size of kernel\n",
        "*   $p$: size of padding\n",
        "*   $s$: size of stride\n",
        "\n",
        "\n",
        "The height of the output image will be given by\n",
        "$$\n",
        "n_{out} = \\left \\lfloor \\frac{n_{in} + 2p - k}{s} \\right \\rfloor + 1,\n",
        "$$\n",
        "\n",
        "where $\\lfloor \\cdot \\rfloor$ is the floor function.\n",
        "\n",
        "In-between conv2d layers we can apply an activation function (e.g. ReLU), batchnorm and pooling layers. Pooling layers apply an operation within a window of pixels defined by a size and a stride.\n",
        "\n",
        "We can now define the structure of our convolutional neural network. The first part of the network will involve convolutional layers, and the second part will be made up of fully connected layers. Assume we have an input image $x$ of size $3 \\times 32 \\times 32$ (number of channels and image dimensions). We will use the following:\n",
        "1. The input goes into a convolutional layer (3 input channels, 6 output channels, kernel of size 5x5, stride 1, padding 1), followed by a ReLU activation and maxpool layer (size 2, stride 2)\n",
        "2. The output from the previous operation goes into another convolutional layer (6 input channels, 16 output channels, kernel of size 5x5, stride 2, padding 1) followed by ReLU\n",
        "3. Then add a flatten layer to flatten all dimensions except the first one: x = torch.flatten(x, 1)\n",
        "4. Then there will be two linear layers + ReLU's and a final linear layer.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "rDB163jt1XfR"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    # in the init function we will just define several layers that we can later use\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5, stride=1, padding=1) # convolutional layer\n",
        "        # what is the size of the object after the above convolution? original image is 32x32; after convolution\n",
        "        # it will be floor((32 + 2*1 - 5)/1) + 1 = 30 -> 30x30\n",
        "\n",
        "        # a pooling layer: it 'pools' together 2x2 of the inputs by keeping only the maximum value\n",
        "        # and uses a stride of 2\n",
        "        self.pool = nn.MaxPool2d(2, stride=2)\n",
        "        # after pooling size is 15x15 (see: https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=2, padding=1) # convolutional layer\n",
        "        # size after convolution: floor((15 + 2*1 - 5)/2) + 1 = 7 -> 7x7\n",
        "\n",
        "        self.fc1 = nn.Linear(16 * 7 * 7, 512)\n",
        "        self.fc2 = nn.Linear(512, 128)\n",
        "        self.fc3 = nn.Linear(128, 10)\n",
        "\n",
        "    # here we define the forward pass, i.e. how our input x is modified as it moves through the network\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x))) # size after operation: 15x15\n",
        "        '''Finish'''\n",
        "        return x\n",
        "\n",
        "net = Net()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrhLaaJNpVJd"
      },
      "source": [
        "Let's write a training function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "k9GyXliLpYLD"
      },
      "outputs": [],
      "source": [
        "def train(model, nr_epochs, optimizer, criterion):\n",
        "    losses = [] # store the losses\n",
        "\n",
        "    for epoch in range(0, nr_epochs):\n",
        "        print(f'Epoch {epoch}')\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            # get the inputs; data is a list of [inputs, labels]\n",
        "            images, labels = data\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "            # Compute the output for all the images in the batch_size; remember we set a batch_size of 10 in the beginning!\n",
        "            outputs = model(images)\n",
        "            # Compute the loss value\n",
        "            loss = criterion(outputs, labels)\n",
        "            # Compute the gradients\n",
        "            loss.backward()\n",
        "            # Take the optimisation step\n",
        "            optimizer.step()\n",
        "\n",
        "            # print statistics\n",
        "            losses += [loss.item()]\n",
        "            if i % 100 == 0:    # print every 1000 iterations\n",
        "                print(i, loss.item())\n",
        "\n",
        "    print('Finished Training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xn1NOtb51hOY"
      },
      "outputs": [],
      "source": [
        "train(model=net, nr_epochs=20, optimizer=optim.SGD(net.parameters(), lr=0.01, momentum=0.9), criterion=nn.CrossEntropyLoss())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7W4rg89wknhD"
      },
      "source": [
        "We can now evaluate the model on test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "UZK0ly3PtP99"
      },
      "outputs": [],
      "source": [
        "def accuracy(model):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    # since we're not training, we don't need to calculate the gradients for our outputs; therefore there\n",
        "    # is no need to store the computational graph in between\n",
        "    with torch.no_grad():\n",
        "        for data in testloader: #iterate over all the test images\n",
        "            images, labels = data\n",
        "            # calculate outputs by running images through the network\n",
        "            outputs = model(images)\n",
        "            # the class with the highest energy is what we choose as prediction\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            # compute the total number of images processed by adding the number of images in each batch\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f'Accuracy of the network on the test images: {100 * correct // total} %')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "P2LD-B3J1lFe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "4cdde618-1ad9-4bef-e637-59cbf484188a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "The size of tensor a (15) must match the size of tensor b (128) at non-singleton dimension 2",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-497618452.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-3454144266.py\u001b[0m in \u001b[0;36maccuracy\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;31m# compute the total number of images processed by adding the number of images in each batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Accuracy of the network on the test images: {100 * correct // total} %'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (15) must match the size of tensor b (128) at non-singleton dimension 2"
          ]
        }
      ],
      "source": [
        "accuracy(net)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgDbosl6qkI0"
      },
      "source": [
        "# Task: implement your own Convolutional Neural Network\n",
        "\n",
        "Change the architecture, number of batches (we defined this when we loaded the data in one of the first cells) and number of epochs to see how this changes what the network has learned.\n",
        "\n",
        "Remember: machine learning is quite tricky with lots of hyperparameter tuning required. A large part of the job is trying to find the right combinations of parameters that work."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "TTFrjsxAteui"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    \"\"\" Write your own CNN architecture \"\"\"\n",
        "\n",
        "    # in the init function we will just define several layers that we can later use\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5, stride=1, padding=1) # convolutional layer\n",
        "        # what is the size of the object after the above convolution? original image is 32x32; after convolution\n",
        "        # it will be floor((32 + 2*1 - 5)/1) + 1 = 30 -> 30x30\n",
        "\n",
        "        # a pooling layer: it 'pools' together 2x2 of the inputs by keeping only the maximum value\n",
        "        # and uses a stride of 2\n",
        "        self.pool = nn.MaxPool2d(2, stride=2)\n",
        "        # after pooling size is 15x15 (see: https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=2, padding=1) # convolutional layer\n",
        "        # size after convolution: floor((15 + 2*1 - 5)/2) + 1 = 7 -> 7x7\n",
        "\n",
        "        self.fc1 = nn.Linear(16 * 7 * 7, 512)\n",
        "        self.fc2 = nn.Linear(512, 128)\n",
        "        self.fc3 = nn.Linear(128, 10)\n",
        "\n",
        "    # here we define the forward pass, i.e. how our input x is modified as it moves through the network\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x))) # size after operation: 15x15\n",
        "        '''Finish'''\n",
        "        return x\n",
        "\n",
        "net = Net()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bc94f610"
      },
      "source": [
        "# Understanding what our network has learned"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeW1gH-U9BwC"
      },
      "source": [
        "For this part, we will use the following larger model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "y5bLsFLl9I6B"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    # in the init function we will just define several layers that we can later use\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        #parameters: in_channels, out_channels, kernel_size\n",
        "        self.conv1 = nn.Conv2d(3, 64, 3)\n",
        "        self.conv2 = nn.Conv2d(64, 128, 3)\n",
        "        self.conv3 = nn.Conv2d(128, 256, 3)\n",
        "        self.conv4 = nn.Conv2d(256, 256, 3)\n",
        "        self.pool = nn.MaxPool2d(2, stride=2)\n",
        "        self.fc1 = nn.Linear(1024, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    # here we define the forward pass, i.e. how our input x is modified as it moves through the network\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "    # let's also define a method to access a layer of choice's output; we will use this later to perform the forward pass up to a certain layer for visualization (e.g. line 1-2 in the forward method)\n",
        "    def forward_partial(self, x):\n",
        "        '''Fill in'''\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-wUIQO-Q35Z"
      },
      "source": [
        "Let's train the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgOWacMG9kkZ",
        "outputId": "f9b1688a-65fa-4d5f-864f-79de10859814"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0\n",
            "0 2.301109552383423\n",
            "100 2.308624029159546\n",
            "200 2.297975778579712\n",
            "300 2.2442798614501953\n",
            "Epoch 1\n",
            "0 1.9280025959014893\n",
            "100 1.7310004234313965\n",
            "200 1.567863941192627\n",
            "300 1.5658446550369263\n",
            "Epoch 2\n",
            "0 1.5410046577453613\n",
            "100 1.496544361114502\n",
            "200 1.3937658071517944\n",
            "300 1.5249311923980713\n",
            "Epoch 3\n",
            "0 1.2127786874771118\n",
            "100 1.4256267547607422\n",
            "200 1.2893810272216797\n",
            "300 1.2039676904678345\n",
            "Epoch 4\n",
            "0 0.9661027789115906\n",
            "100 1.076302409172058\n",
            "200 1.173989176750183\n",
            "300 1.1181620359420776\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "net = Net()\n",
        "train(model=net, nr_epochs=5, optimizer=optim.SGD(net.parameters(), lr=0.01, momentum=0.9), criterion=nn.CrossEntropyLoss())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rNs48GRBJJk",
        "outputId": "0d13c750-affd-41ee-bc2d-77c78ee51405"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the test images: 64 %\n"
          ]
        }
      ],
      "source": [
        "accuracy(net)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abec05a6"
      },
      "source": [
        "Now, we would like to understand what the network has actually learned. The work in: https://ai.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html does something similar, so check it out if you're interested.\n",
        "\n",
        "Consider that we pass a certain image $\\tilde{x}$ through the network and get the output $z^n$ from the neural network.\n",
        "\n",
        "Based on that output we would like to reconstruct the input to better understand how well our neural network has learned the original image. Denote with $\\hat z^n$ the output from the same layer for some input $x$.\n",
        "\n",
        "Consider then the squared error loss\n",
        "$$\n",
        "\\mathcal{L}(z^n, \\hat z^n) = ||z^n-\\hat z^n||_2^2,\n",
        "$$\n",
        "\n",
        "We will give the network a certain input image $\\tilde x$ and obtain the layer values for that image $z^n$. We assume we only observe $z^n$, but want to *reconstruct* $\\tilde x$. To do that we will optimise over the $x$ that gets us as close as possible to that layer output:\n",
        "$$\n",
        "x^* = \\arg\\min_{x} \\mathcal{L}(z^n, \\hat z^n).\n",
        "$$\n",
        "\n",
        "We will further follow the work of https://arxiv.org/pdf/1412.0035v1.pdf\n",
        "\n",
        "It can be useful to restrict the reconstruction to the subset of natural images - in order to make the above reconstruction better (and easier to interpret). In order to do so, we need to define the properties that natural images have. A proxy used in the above paper is to incorporate in the reconstruction an appropriate image prior. As in the paper, we will try two things:\n",
        "\n",
        "1. the $\\alpha$-norm: $R(x) = ||x||_{\\alpha}^{\\alpha}$ where $x$ is the vectorised and meansubtracted image. With this regularisation we force the image values to stay within a certain range.\n",
        "\n",
        "2. the total variation encouraging images to consist of piece-wise constant patches: $R(x) = \\sum_{i,j} \\left((x_{i,j+1}-x_{ij})^2 + (x_{i+1,j}-x_{ij})^2\\right)^{\\frac{\\beta}{2}}$ where $x\\in\\mathbb{R}^{H\\times W}$ with $H$ the height and $W$ the width.\n",
        "\n",
        "We will add the above terms as regularisers to our loss function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "645a029f"
      },
      "outputs": [],
      "source": [
        "# Define our new criteria:\n",
        "def R_1(img, alpha):\n",
        "    img = torch.flatten(img)\n",
        "    R1 = torch.linalg.norm(img, ord=alpha)\n",
        "    return R1\n",
        "\n",
        "def R_2(img, beta):\n",
        "    R2 = torch.sum(torch.pow(torch.flatten(torch.pow(img[:,:,:,1:] - img[:,:,:,:-1], 2)) \\\n",
        "                                + torch.flatten(torch.pow(img[:,:,1:,:] - img[:,:,:-1,:], 2)), beta/2))\n",
        "    return R2\n",
        "\n",
        "# Load a new batch of data\n",
        "dataiter = iter(trainloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3e44171"
      },
      "source": [
        "Let us now implement the optimisation scheme. We will begin by initialising a random image, then minimising the loss criterion that we discussed above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "OiHJFMA17zRp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4ae4baab-843c-4a30-99c9-90d63e0f103c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3166.1826171875\n",
            "407.7789306640625\n",
            "2742.56640625\n",
            "472.29681396484375\n",
            "2661.51171875\n",
            "543.6793823242188\n",
            "2587.844482421875\n",
            "709.35791015625\n",
            "2458.468505859375\n",
            "760.00146484375\n",
            "2399.5751953125\n",
            "819.0775756835938\n",
            "2345.907958984375\n",
            "858.2740478515625\n",
            "2355.485107421875\n",
            "838.1521606445312\n",
            "2337.407470703125\n",
            "836.4387817382812\n",
            "2336.132568359375\n",
            "942.9072875976562\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Get some image\n",
        "images, labels = next(dataiter)\n",
        "img = images[0] # take just the first image; the above thing is an array of images of size batchsize\n",
        "img = img / 2 + 0.5     # unnormalize\n",
        "\n",
        "# Print the original image\n",
        "npimg = img.numpy() # translate to numpy\n",
        "npimg_t = np.transpose(npimg, (1, 2, 0)) # transpose things\n",
        "plt.imshow(npimg_t)\n",
        "plt.title(str(classes[labels[0]]))\n",
        "plt.show()\n",
        "\n",
        "# Pass the image through the network and get the layer output\n",
        "true_out = net.forward_partial(images[0:1,:,:,:])\n",
        "\n",
        "# Optimise the output from the layer for some random input to get close to the output for the original image\n",
        "sample_image = torch.rand(1, 3, 32, 32)\n",
        "sample_image.requires_grad = True\n",
        "nr_its_in = 100000\n",
        "lr = 0.0001\n",
        "for it in range(nr_its_in):\n",
        "    sample_out = net.forward_partial(sample_image)\n",
        "    sample_loss = torch.sum(torch.pow(true_out.detach() - sample_out, 2)) \\\n",
        "            + 0.05 * R_1(sample_image, 6) + 0.1 * R_2(sample_image, beta=2)\n",
        "    sample_loss.backward()\n",
        "    # Perform the gradient step to improve the sample_image\n",
        "    with torch.no_grad():\n",
        "        sample_image -= lr*sample_image.grad #+ 0.001*torch.rand(sample_image.shape)\n",
        "    if it%5000==0:\n",
        "        print(sample_loss.item())\n",
        "\n",
        "# Print reconstructed image\n",
        "numpy_image = sample_image.detach().numpy()\n",
        "# Constrain to the right range\n",
        "numpy_image += np.abs(numpy_image.min())\n",
        "numpy_image /= numpy_image.max()\n",
        "numpy_image = np.transpose(numpy_image[0,:,:,:], (1, 2, 0))\n",
        "plt.imshow(numpy_image)\n",
        "plt.title(classes[labels[0]])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7c74dbc8"
      },
      "source": [
        "Run the above code multiple times - for certain images the reconstruction works better than for others.\n",
        "\n",
        "## Task:\n",
        "Try to change the layer whose output we use. You can do this by modifying the forward_partial function we defined in the neural network class. Are any particular layers better at reconstructing the image?\n",
        "\n",
        "Also try to add or remove the noise - is there any difference in training with noise? Try also changing the parameters to see if you can find a configuration which obtains better results than what I managed to obtain.\n",
        "\n",
        "What do you think of the above? We can in general reconstruct something even with our relatively simple model (compared to the architectures Google and so on use). What if the input image contained sensitive information? Can you think that the above is a privacy or security risk?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fC1vRy8410sV"
      },
      "source": [
        "# ResNet\n",
        "\n",
        "Let's now try to code a different model. We will follow the architecture of ResNet (see https://arxiv.org/pdf/1512.03385.pdf), which has had a significant impact on the architectures we use in many models due to introducing the idea of skip connections.\n",
        "\n",
        "ResNet is divided into building blocks called Residual blocks, which are made up of convolutional layers. Let $F$ define a non-linear mapping (such as a sequence of convolutional layers, activation functions, etc.). CNNs such as the previous one we coded would typically model the output of a collection of convolutional layers as\n",
        "$$\n",
        "x_{l+1} = F(x_l).\n",
        "$$\n",
        "ResNet adds the input to the output of the block, so that\n",
        "$$\n",
        "x_{l+1} = x_l + F(x_l).\n",
        "$$\n",
        "This identity addition is what we call a **skip connection**. Note that it does not add computational complexity to $F$. When we apply backpropagation on the Residual block, we obtain\n",
        "$$\n",
        "\\frac{\\partial x_{l+1}}{\\partial x_l} = I + \\frac{\\partial F}{\\partial x_l},\n",
        "$$\n",
        "where $I$ is the identity matrix, instead of\n",
        "$$\n",
        "\\frac{\\partial x_{l+1}}{\\partial x_l} = \\frac{\\partial F}{\\partial x_l}.\n",
        "$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmBytbPF33zl"
      },
      "source": [
        "##Residual Blocks\n",
        "\n",
        "Let's begin by coding a residual block. Let $x$ be the input to the residual block. The structure of the residual blocks will be:\n",
        "\n",
        " input -> convolutional layer 1 -> batchnorm -> ReLU -> convolutional layer 2 -> batchnorm + input -> ReLU.\n",
        "\n",
        "Before applying the ReLU activation function after the second convolutional layer, we add the input of the block to the output (we call this the residual). **The parameters of the residual blocks are defined in order to either preserve or decrease the dimensions (height and width) of the input.** If the dimensions are preserved, then we can simply add the input at the end of the residual block, if the dimensions are decreased, we also downsample the input so that the dimensions match.\n",
        "\n",
        "Parameters:\n",
        "*   in_channels: number of input channels into residual block\n",
        "*   out_channels: number of output channels out of residual block\n",
        "*   stride: size of stride of **first convolutional layer** (this layer will determine if the output of the residual block has the same dimensionality or different to the input)\n",
        "*   reduce_dim: this is a boolean to define if we want to reduce the dimensionality of the input or not. If so, we will apply a 1x1 convolution with stride 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "TDBt_rzn1_w6"
      },
      "outputs": [],
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1, reduce_dim=False):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size = 3, stride = stride, padding = 1) # first convolutional layer\n",
        "        # size after convolution: n_out = floor((n_in + 2*1 - 3)/stride) + 1\n",
        "        # check that when stride=1 n_out = n_in, when stride=2 n_out = floor((n_in - 1)/2) + 1\n",
        "\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size = 3, stride = 1, padding = 1) # second convolutional layer\n",
        "        # size after convolution: n_out = floor((n_in + 2*1 - 3)/1) + 1 = n_in so size is preserved\n",
        "\n",
        "        self.reduce_dim = reduce_dim\n",
        "        self.downsample = nn.Conv2d(in_channels, out_channels, kernel_size = 1, stride = 2, padding = 0) # convolutional layer to reduce dimensionality of the input\n",
        "        # size after convolution: n_out = floor((n_in - 1)/2) + 1\n",
        "        # this is the same dimensionality as what we obtain after applying conv1 with stride=2 followed by conv2\n",
        "\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.out_channels = out_channels\n",
        "\n",
        "    def forward(self, x):\n",
        "        '''Fill in'''\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XuZSBgMFJJj"
      },
      "source": [
        "## Architecture\n",
        "\n",
        "The ResNet architecture consists of input convolutional layers, groups of Residual Blocks and some output linear layers.\n",
        "\n",
        "Input layers -> Residual blocks -> Output layers\n",
        "\n",
        "Of all the Residual Blocks, only some of them will reduce the dimensionality of the input. For example, if ResNet has [3, 3, 3] blocks, then we have 3 times a group of 3 blocks. **Dimensionality reduction will occur in the first residual block of each group, excluding the first group.** In the case of [3, 3, 3] dimensionality reduction occurs in the fourth and seventh residual blocks. ResNets are usually implemented with more residual blocks (that shows a better performance), however we will code a smaller version with the structure [3, 3, 3].\n",
        "\n",
        "Structure of input layers:\n",
        "\n",
        "1.   Convolutional layer (3 input channels, 32 output channels, kernel of size 7x7, stride 2, padding 3), followed by batchnorm and a ReLU activation\n",
        "2.   Maxpool (kernel of size 3x3, stride 2, padding 1)\n",
        "\n",
        "Structure of output layers:\n",
        "\n",
        "1.   Averagepool (kernel of size 2x2, , stride 1, padding 0)\n",
        "2.   Linear layer\n",
        "\n",
        "We will use the function _make_group to add the groups of residual blocks described above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "iEtswIC6u5ya"
      },
      "outputs": [],
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, groups, num_classes = 10):\n",
        "        super(ResNet, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=7, stride=2, padding=3)\n",
        "        self.bn = nn.BatchNorm2d(32)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
        "\n",
        "        self.inplanes = 32 # define the number of channels of the input of the first residual block (this will be updated as the residual blocks are added to the network)\n",
        "\n",
        "        # groups of residual blocks\n",
        "        self.group0 = self._make_group(block, 32, groups[0], stride = 1)\n",
        "        self.group1 = self._make_group(block, 64, groups[1], stride = 2)\n",
        "        self.group2 = self._make_group(block, 128, groups[2], stride = 2)\n",
        "\n",
        "        self.avgpool = nn.AvgPool2d(2, stride=1)\n",
        "        self.fc = nn.Linear(128, num_classes)\n",
        "\n",
        "    def _make_group(self, block, planes, blocks, stride=1):\n",
        "        '''\n",
        "        block: residual block used in model\n",
        "        planes: int, number of channels the output of group should have\n",
        "        stride: int, size of stride of first convolutional layer of first residual block in group\n",
        "        '''\n",
        "        reduce_dim=False\n",
        "\n",
        "        # first residual block in group\n",
        "        if stride != 1 or self.inplanes != planes: # we reduce dimensionality when stride=2 or if the input and output channels into the residual block do not match\n",
        "            reduce_dim=True\n",
        "        group = []\n",
        "        group.append(block(self.inplanes, planes, stride, reduce_dim)) # add residual block to list\n",
        "        self.inplanes = planes # update number of channels of input to next residual block (according to output of current residual block)\n",
        "\n",
        "        # remaining residual blocks in group\n",
        "        for i in range(1, blocks):\n",
        "            group.append(block(self.inplanes, planes))\n",
        "\n",
        "        return nn.Sequential(*group)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # input layers\n",
        "        x = self.relu(self.bn(self.conv1(x)))\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        # groups of residual blocks\n",
        "        x = self.group0(x)\n",
        "        x = self.group1(x)\n",
        "        x = self.group2(x)\n",
        "\n",
        "        # output layers\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1) # flatten all dimensions except batch\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VzB06TU_8qA"
      },
      "source": [
        "Let's train the model. You can also compare different architectures (instead of [3, 3, 3]) to see what produces the best accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "U6YwUeB52akB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "7ac37fd5-25ad-4c64-d6d2-d337c6eda4fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'out' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3631117283.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mresnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mResidualBlock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# total number of residual blocks is 9\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnr_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-4214890740.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, nr_epochs, optimizer, criterion)\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;31m# Compute the output for all the images in the batch_size; remember we set a batch_size of 10 in the beginning!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0;31m# Compute the loss value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-655478100.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;31m# groups of residual blocks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2520862965.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;34m'''Fill in'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'out' is not defined"
          ]
        }
      ],
      "source": [
        "resnet = ResNet(block=ResidualBlock, groups=[3, 3, 3]) # total number of residual blocks is 9\n",
        "train(model=resnet.train(), nr_epochs=15, optimizer=optim.SGD(resnet.parameters(), lr=0.01, momentum = 0.9), criterion=nn.CrossEntropyLoss())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AULFeQN_A4R5"
      },
      "source": [
        "Let's evaluate the ResNet on the test set. We can compare the performance to the previous CNN we coded."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CuDYubul2fRJ"
      },
      "outputs": [],
      "source": [
        "accuracy(resnet.eval())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3M7JiLpzEMzV"
      },
      "source": [
        "# Task: implement Pre-Activation Residual Blocks\n",
        "\n",
        "One of the variants of ResNet involves using Residual Blocks with a different architecture. Let's look at Pre-Activation Residual Blocks. In the original model, the activation function (in our case the ReLU function) is applied after the skip connection. In the pre-activation variant, the batchnorm and ReLU function are applied **at the beginning of the residual block**:\n",
        "\n",
        "input -> batchnorm -> ReLU -> convolutional layer 1 -> batchnorm -> ReLU -> convolutional layer 2 + input\n",
        "\n",
        "Note that the input layers of ResNet will have to be modified: the batchnorm and ReLU in the input layers will have to be removed in order to not be applied twice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PkyhcHfWLb0n"
      },
      "outputs": [],
      "source": [
        "class PreActivationResidualBlock(nn.Module):\n",
        "    '''Fill in'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uL7l3OXTLoBw"
      },
      "outputs": [],
      "source": [
        "pre_act_resnet = ResNet(block=PreActivationResidualBlock, groups=[3, 3, 3])\n",
        "train(model=pre_act_resnet.train(), nr_epochs=15, optimizer=optim.SGD(pre_act_resnet.parameters(), lr=0.01, momentum = 0.9), criterion=nn.CrossEntropyLoss())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5_Lq8kVlL-eZ"
      },
      "outputs": [],
      "source": [
        "accuracy(pre_act_resnet.eval())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1_qlA_PQk-x"
      },
      "source": [
        "The Pre-activation ResNet has been shown to perform better than the original ResNet for very deep networks. Is the same true in our shallow setting?\n",
        "\n",
        "Feel free to experiment with other structures of residual blocks (see Figure 4 in https://arxiv.org/pdf/1603.05027.pdf)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQjnLorgZ80R"
      },
      "source": [
        "# References\n",
        "\n",
        "\n",
        "\n",
        "*   Aravindh Mahendran and Andrea Vedaldi (2014). Understanding deep image representations by inverting them. Arxiv: https://arxiv.org/abs/1412.0035\n",
        "*   Kaiming He, Xiangyu Zhang, Shaoqing Ren and Jian SunDeep (2015). Residual Learning for Image Recognition. Arxiv: https://arxiv.org/pdf/1512.03385.pdf\n",
        "*   Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun (2016). Identity Mappings in Deep Residual Networks. Arxiv: https://arxiv.org/pdf/1603.05027.pdf\n",
        "*   https://blog.paperspace.com/writing-resnet-from-scratch-in-pytorch/\n",
        "*   https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial5/Inception_ResNet_DenseNet.html#ResNet\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}